{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Getting the SEED dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 load the matlab format files and take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from scipy import io\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = \"./Preprocessed_EEG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1_1 = scipy.io.loadmat('./Preprocessed_EEG/1_20131027.mat')\n",
    "raw_1_2 = scipy.io.loadmat('./Preprocessed_EEG/1_20131030.mat')\n",
    "raw_1_3 = scipy.io.loadmat('./Preprocessed_EEG/1_20131107.mat')\n",
    "# raw_2_1 = scipy.io.loadmat('./Preprocessed_EEG/2_20140404.mat')\n",
    "label = scipy.io.loadmat('./Preprocessed_EEG/label.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['__header__', '__version__', '__globals__', 'djc_eeg1', 'djc_eeg2', 'djc_eeg3', 'djc_eeg4', 'djc_eeg5', 'djc_eeg6', 'djc_eeg7', 'djc_eeg8', 'djc_eeg9', 'djc_eeg10', 'djc_eeg11', 'djc_eeg12', 'djc_eeg13', 'djc_eeg14', 'djc_eeg15']),\n",
       " dict_keys(['__header__', '__version__', '__globals__', 'djc_eeg1', 'djc_eeg2', 'djc_eeg3', 'djc_eeg4', 'djc_eeg5', 'djc_eeg6', 'djc_eeg7', 'djc_eeg8', 'djc_eeg9', 'djc_eeg10', 'djc_eeg11', 'djc_eeg12', 'djc_eeg13', 'djc_eeg14', 'djc_eeg15']),\n",
       " dict_keys(['__header__', '__version__', '__globals__', 'djc_eeg1', 'djc_eeg2', 'djc_eeg3', 'djc_eeg4', 'djc_eeg5', 'djc_eeg6', 'djc_eeg7', 'djc_eeg8', 'djc_eeg9', 'djc_eeg10', 'djc_eeg11', 'djc_eeg12', 'djc_eeg13', 'djc_eeg14', 'djc_eeg15']),\n",
       " dict_keys(['__header__', '__version__', '__globals__', 'label']))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_1_1.keys(), raw_1_2.keys(), raw_1_3.keys(), label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'djc_eeg1', 'djc_eeg2', 'djc_eeg3', 'djc_eeg4', 'djc_eeg5', 'djc_eeg6', 'djc_eeg7', 'djc_eeg8', 'djc_eeg9', 'djc_eeg10', 'djc_eeg11', 'djc_eeg12', 'djc_eeg13', 'djc_eeg14', 'djc_eeg15'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_1_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62, 46601), (62, 46601), (62, 47401), (62, 47401))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_1_1['djc_eeg2'].shape, raw_1_2['djc_eeg2'].shape, raw_1_1['djc_eeg10'].shape, raw_1_3['djc_eeg10'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw_1_1['djc_eeg1']:\n",
    "- raw_1_1: the raw eeg data, the 1st subject(out of 15 subjects), the 1st experiments(out of 3 experiments)\n",
    "- 'djc_eeg1': djc could possibly mean the name of the subject(which leaks the privacy XD), and 'eeg1' represents it is the 1st trial(out of 15 trials)\n",
    "- 62: n_channels\n",
    "- 47001: roughly 4 mins(240sec * 200 Hz sampling rate) the eeg signal during watching the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0, -1, -1,  0,  1, -1,  0,  1,  1,  0, -1,  0,  1, -1],\n",
       "      dtype=int16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Create the torch dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 cut compute windows\n",
    "\n",
    "since a movie clip contains eeg signals of ~240 seconds with sf=200Hz, I decide to cut them into 4 sec windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_window = 200 * 4\n",
    "\n",
    "raw_X = []\n",
    "raw_y = []\n",
    "\n",
    "prefix = 'djc_eeg'\n",
    "\n",
    "# raw_1_1\n",
    "for i in range(1, 16):\n",
    "    data = raw_1_1[prefix + str(i)]\n",
    "    # print(data.shape)\n",
    "    n_windows = data.shape[1] // len_window\n",
    "    # print(n_windows)\n",
    "    reshaped_X = np.reshape(data[:, :n_windows * len_window], (62, len_window, n_windows))\n",
    "    raw_X.append(reshaped_X)\n",
    "    raw_y.append(np.array([label['label'][0][i-1] for j in range(n_windows)]))\n",
    "\n",
    "# raw_1_2\n",
    "for i in range(1, 16):\n",
    "    data = raw_1_2[prefix + str(i)]\n",
    "    # print(data.shape)\n",
    "    n_windows = data.shape[1] // len_window\n",
    "    # print(n_windows)\n",
    "    reshaped_X = np.reshape(data[:, :n_windows * len_window], (62, len_window, n_windows))\n",
    "    raw_X.append(reshaped_X)\n",
    "    raw_y.append(np.array([label['label'][0][i-1] for j in range(n_windows)]))\n",
    "    # print(reshaped_X.shape)   # print(reshaped_X.shape)\n",
    "\n",
    "# raw_1_3\n",
    "for i in range(1, 16):\n",
    "    data = raw_1_3[prefix + str(i)]\n",
    "    # print(data.shape)\n",
    "    n_windows = data.shape[1] // len_window\n",
    "    # print(n_windows)\n",
    "    reshaped_X = np.reshape(data[:, :n_windows * len_window], (62, len_window, n_windows))\n",
    "    raw_X.append(reshaped_X)\n",
    "    raw_y.append(np.array([label['label'][0][i-1] for j in range(n_windows)]))\n",
    "    # print(reshaped_X.shape)   # print(reshaped_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 800, 2526)\n",
      "(2526,)\n"
     ]
    }
   ],
   "source": [
    "concat_X = np.concatenate(raw_X, axis=2)\n",
    "print(concat_X.shape)\n",
    "concat_y = np.concatenate(raw_y)\n",
    "print(concat_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., -1, -1, -1], dtype=int16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2526 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2\n",
       "0     0  0  1\n",
       "1     0  0  1\n",
       "2     0  0  1\n",
       "3     0  0  1\n",
       "4     0  0  1\n",
       "...  .. .. ..\n",
       "2521  1  0  0\n",
       "2522  1  0  0\n",
       "2523  1  0  0\n",
       "2524  1  0  0\n",
       "2525  1  0  0\n",
       "\n",
       "[2526 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(concat_y)\n",
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot encoding\n",
    "- positive:  1 => [0, 0 ,1]\n",
    "- neutral:   0 => [0, 1, 0]\n",
    "- negative: -1 => [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2526, 3), (62, 800, 2526))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, concat_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Create EEG-conformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from braindecode.models import EEGConformer\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "from eegconformer import EEGConformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "device = \"cuda\" if cuda else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.7'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_version = torch.version.cuda\n",
    "cuda_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/BCI-emotion-recognition/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 62, 800]              [1, 3]                    --                        --\n",
      "â”œâ”€_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 62, 800]           [1, 47, 40]               --                        --\n",
      "â”‚    â””â”€Sequential (shallownet): 2-1                          [1, 1, 62, 800]           [1, 40, 1, 47]            --                        --\n",
      "â”‚    â”‚    â””â”€Conv2d (0): 3-1                                  [1, 1, 62, 800]           [1, 40, 62, 776]          1,040                     [1, 25]\n",
      "â”‚    â”‚    â””â”€Conv2d (1): 3-2                                  [1, 40, 62, 776]          [1, 40, 1, 776]           99,240                    [62, 1]\n",
      "â”‚    â”‚    â””â”€BatchNorm2d (2): 3-3                             [1, 40, 1, 776]           [1, 40, 1, 776]           80                        --\n",
      "â”‚    â”‚    â””â”€ELU (3): 3-4                                     [1, 40, 1, 776]           [1, 40, 1, 776]           --                        --\n",
      "â”‚    â”‚    â””â”€AvgPool2d (4): 3-5                               [1, 40, 1, 776]           [1, 40, 1, 47]            --                        [1, 75]\n",
      "â”‚    â”‚    â””â”€Dropout (5): 3-6                                 [1, 40, 1, 47]            [1, 40, 1, 47]            --                        --\n",
      "â”‚    â””â”€Sequential (projection): 2-2                          [1, 40, 1, 47]            [1, 47, 40]               --                        --\n",
      "â”‚    â”‚    â””â”€Conv2d (0): 3-7                                  [1, 40, 1, 47]            [1, 40, 1, 47]            1,640                     [1, 1]\n",
      "â”‚    â”‚    â””â”€Rearrange (1): 3-8                               [1, 40, 1, 47]            [1, 47, 40]               --                        --\n",
      "â”œâ”€_TransformerEncoder (transformer): 1-2                     [1, 47, 40]               [1, 47, 40]               --                        --\n",
      "â”‚    â””â”€_TransformerEncoderBlock (0): 2-3                     [1, 47, 40]               [1, 47, 40]               --                        --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (0): 3-9                            [1, 47, 40]               [1, 47, 40]               6,640                     --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (1): 3-10                           [1, 47, 40]               [1, 47, 40]               13,080                    --\n",
      "â”‚    â””â”€_TransformerEncoderBlock (1): 2-4                     [1, 47, 40]               [1, 47, 40]               --                        --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (0): 3-11                           [1, 47, 40]               [1, 47, 40]               6,640                     --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (1): 3-12                           [1, 47, 40]               [1, 47, 40]               13,080                    --\n",
      "â”‚    â””â”€_TransformerEncoderBlock (2): 2-5                     [1, 47, 40]               [1, 47, 40]               --                        --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (0): 3-13                           [1, 47, 40]               [1, 47, 40]               6,640                     --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (1): 3-14                           [1, 47, 40]               [1, 47, 40]               13,080                    --\n",
      "â”‚    â””â”€_TransformerEncoderBlock (3): 2-6                     [1, 47, 40]               [1, 47, 40]               --                        --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (0): 3-15                           [1, 47, 40]               [1, 47, 40]               6,640                     --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (1): 3-16                           [1, 47, 40]               [1, 47, 40]               13,080                    --\n",
      "â”‚    â””â”€_TransformerEncoderBlock (4): 2-7                     [1, 47, 40]               [1, 47, 40]               --                        --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (0): 3-17                           [1, 47, 40]               [1, 47, 40]               6,640                     --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (1): 3-18                           [1, 47, 40]               [1, 47, 40]               13,080                    --\n",
      "â”‚    â””â”€_TransformerEncoderBlock (5): 2-8                     [1, 47, 40]               [1, 47, 40]               --                        --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (0): 3-19                           [1, 47, 40]               [1, 47, 40]               6,640                     --\n",
      "â”‚    â”‚    â””â”€_ResidualAdd (1): 3-20                           [1, 47, 40]               [1, 47, 40]               13,080                    --\n",
      "â”œâ”€_FullyConnected (fc): 1-3                                  [1, 47, 40]               [1, 32]                   --                        --\n",
      "â”‚    â””â”€Sequential (fc): 2-9                                  [1, 1880]                 [1, 32]                   --                        --\n",
      "â”‚    â”‚    â””â”€Linear (0): 3-21                                 [1, 1880]                 [1, 256]                  481,536                   --\n",
      "â”‚    â”‚    â””â”€ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "â”‚    â”‚    â””â”€Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "â”‚    â”‚    â””â”€Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "â”‚    â”‚    â””â”€ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "â”‚    â”‚    â””â”€Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "â”œâ”€_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 3]                    --                        --\n",
      "â”‚    â””â”€Sequential (final_layer): 2-10                        [1, 32]                   [1, 3]                    --                        --\n",
      "â”‚    â”‚    â””â”€Linear (0): 3-27                                 [1, 32]                   [1, 3]                    99                        --\n",
      "â”‚    â”‚    â””â”€LogSoftmax (classification): 3-28                [1, 3]                    [1, 3]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 710,179\n",
      "Trainable params: 710,179\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 127.73\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 16.90\n",
      "Params size (MB): 2.84\n",
      "Estimated Total Size (MB): 19.94\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "seed = 20240216\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "model = EEGConformer(\n",
    "    n_outputs=3,\n",
    "    n_chans=62,\n",
    "    n_times=800, # input_winodw_samples\n",
    "    input_window_seconds=4,\n",
    "    sfreq=200,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 prepare the train set / test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62, 800, 2526), (2526, 3))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2526, 62, 800)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = concat_X.transpose((2, 0, 1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1768, 62, 800), (758, 62, 800), (1768, 3), (758, 3))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "x_train_tensor = torch.from_numpy(X_train).to(torch.float32).to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train.values).to(torch.float32).to(device)\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "x_test_tensor = torch.from_numpy(X_test).to(torch.float32).to(device)\n",
    "y_test_tensor = torch.from_numpy(y_test.values).to(torch.float32).to(device)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "test_acc_list = []\n",
    "test_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, x_test, y_test, save_path='./model_transformer/', n_epochs=100):\n",
    "    \"\"\"\n",
    "    the training function.\n",
    "    Attributes:\n",
    "    - model: the instance of the network\n",
    "    - save_path: the path to which the model state will be saved. None means w/o saving.\n",
    "\n",
    "    Return: \n",
    "    the best model if save_path is not None, the last model otherwise\n",
    "    \"\"\"\n",
    "    train_acc_list.clear()\n",
    "    train_loss_list.clear()\n",
    "    test_acc_list.clear()\n",
    "    test_loss_list.clear()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('the model will be trained on: ', device)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        training_loss = 0.0\n",
    "        testing_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        model.train()\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            # print(inputs.shape, labels.shape)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # print(\"lables.size\", labels.shape)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            # print(outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, label = torch.max(labels, 1)\n",
    "            # print(predicted.shape)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "        \n",
    "        train_loss = training_loss / len(train_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_accuracy = correct / total\n",
    "        train_acc_list.append(train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                testing_loss += loss.item()\n",
    "\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                _, label = torch.max(labels, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == label).sum().item()\n",
    "            \n",
    "            test_loss = testing_loss / len(test_loader)\n",
    "            test_loss_list.append(test_loss)\n",
    "            test_accuracy = correct / total\n",
    "            test_acc_list.append(test_accuracy)\n",
    "\n",
    "            if test_accuracy > best_accuracy:\n",
    "                best_accuracy = test_accuracy\n",
    "                if save_path is not None:\n",
    "                    torch.save(model.state_dict(), save_path + 'best_model.pth')\n",
    "                    print(\"best_model found, best acc: \", best_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    if save_path is not None: \n",
    "        model.load_state_dict(torch.load(save_path + 'best_model.pth'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model will be trained on:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 31.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model found, best acc:  1.0\n",
      "Epoch 1/10 - Train Loss: 0.0203 - Train Accuracy: 0.9943 - Test Loss: 0.0002 - Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Loss: 0.0177 - Train Accuracy: 0.9943 - Test Loss: 0.0016 - Test Accuracy: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 31.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Loss: 0.0205 - Train Accuracy: 0.9949 - Test Loss: 0.0022 - Test Accuracy: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train Loss: 0.0481 - Train Accuracy: 0.9836 - Test Loss: 0.0000 - Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 31.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.0556 - Train Accuracy: 0.9893 - Test Loss: 0.0000 - Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 31.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train Loss: 0.1126 - Train Accuracy: 0.9678 - Test Loss: 0.0160 - Test Accuracy: 0.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 31.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train Loss: 0.0231 - Train Accuracy: 0.9943 - Test Loss: 0.0001 - Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 31.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train Loss: 0.0162 - Train Accuracy: 0.9972 - Test Loss: 0.0000 - Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 30.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train Loss: 0.0083 - Train Accuracy: 0.9972 - Test Loss: 0.0000 - Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:01<00:00, 31.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.0344 - Train Accuracy: 0.9910 - Test Loss: 0.0000 - Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "best_model = train(model, X_train, X_test, y_train, y_test, n_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0483d052ddfe31120a94f745be5965e40db576257e66e08bb5a082224a64a3a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
